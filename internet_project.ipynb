{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "I04i7dEcfA0i",
        "GrNJvifDfG7b"
      ],
      "authorship_tag": "ABX9TyOTsXymPLInMuA+BNxc6Uu7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yahav1349/Number-of-steps-preditnios/blob/main/internet_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General"
      ],
      "metadata": {
        "id": "I04i7dEcfA0i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oDSH6W3qcyOF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Modelling\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from zipfile import ZipFile\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def norm(x, y, z):\n",
        "  return np.sqrt(float(x)**2 + float(y)**2 + float(z) **2)\n",
        "\n",
        "def is_float(string):\n",
        "    try:\n",
        "        float(string)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False"
      ],
      "metadata": {
        "id": "eOJZICuSc1Tc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(file_name):\n",
        "  train_list = []\n",
        "  test_list = []\n",
        "  with ZipFile(file_name, \"r\") as f:\n",
        "      for name in f.namelist():\n",
        "        rand = random.uniform(0,1)\n",
        "        if rand >= 0.8:\n",
        "          test_list.append(name)\n",
        "        else:\n",
        "          train_list.append(name)\n",
        "  return train_list, test_list"
      ],
      "metadata": {
        "id": "fxvPIMd7d939"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test(curr_list, bad_files):\n",
        "  mean_norm_list = []\n",
        "  std_norm_list = []\n",
        "  max_norm_list = []\n",
        "  range_list = []\n",
        "  classification_list = []\n",
        "  number_of_steps_list = []\n",
        "  num_rows = []\n",
        "  for i,name in enumerate(curr_list):\n",
        "    if name in bad_files:\n",
        "        data = pd.read_csv(name, skiprows=6)\n",
        "        head = pd.read_csv(name, nrows=4)\n",
        "    else:\n",
        "        data = pd.read_csv(name,skiprows=5)\n",
        "        head = pd.read_csv(name, nrows=3)\n",
        "    classification = head.iloc[1,1]\n",
        "    steps = head.iloc[2,1]\n",
        "    data['Norm'] = [\"\" for i in range(len(data))]\n",
        "    data['Classification'] = [classification for i in range(len(data))]\n",
        "    for row in range(len(data)):\n",
        "      x,y,z = data.iloc[row, 1], data.iloc[row, 2], data.iloc[row, 3]\n",
        "      if  not is_float(x) or not is_float(y) or not is_float(z):\n",
        "        data.drop(data.index[row])\n",
        "      else:\n",
        "        data['Norm'].iloc[row] = norm(x,y,z)\n",
        "    mean_norm_list.append(np.mean(data['Norm']))\n",
        "    std_norm_list.append(np.std(data['Norm']))\n",
        "    max_norm_list.append(np.max(data['Norm']))\n",
        "    range_list.append(np.max(data['Norm']) - np.min(data['Norm']))\n",
        "    classification_list.append(data['Classification'][0])\n",
        "    num_rows.append(len(data))\n",
        "    number_of_steps_list.append(steps)\n",
        "  data_final = {\n",
        "      'Mean Norm': mean_norm_list,\n",
        "      'Std Norm': std_norm_list,\n",
        "      'Max Norm': max_norm_list,\n",
        "      'Range': range_list,\n",
        "      'Number of Rows': num_rows,\n",
        "      'Number of Steps': number_of_steps_list,\n",
        "      'Classification': classification_list\n",
        "  }\n",
        "  # Create the DataFrame\n",
        "  df = pd.DataFrame(data_final)\n",
        "  return df"
      ],
      "metadata": {
        "id": "ZNChNoUVfLXa"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_bad_lines(df):\n",
        "  bad_index = []\n",
        "  for row in range(len(df)):\n",
        "    x,y,z = df.iloc[row, 1], df.iloc[row, 2], df.iloc[row, 3]\n",
        "    if '-' in str(x)[1:] or '-' in str(y)[1:] or '-' in str(z)[1:]:\n",
        "      bad_index.append(row)\n",
        "  return bad_index"
      ],
      "metadata": {
        "id": "Mxwl-s5pvqkI"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_train(train_df, bad_index):\n",
        "  train_df = train_df.drop(train_df.index[[i for i in bad_index]])\n",
        "  # train_df = train_df.iloc[:, :-1]\n",
        "  train_df = train_df.dropna()\n",
        "  return train_df"
      ],
      "metadata": {
        "id": "IlbuXNcLdPVa"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_test(test_df, bad_index):\n",
        "  test_df = test_df.drop(test_df.index[[i for i in bad_index]])\n",
        "  # test_df = test_df[['Time [sec]','ACC X','ACC Y', 'ACC Z',\t'Norm','Classification']]\n",
        "  test_df = test_df.dropna()\n",
        "  return test_df"
      ],
      "metadata": {
        "id": "LTVkANZhOflY"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def null_rows(matrix):\n",
        "  null_list = []\n",
        "  null_values = matrix.isnull()\n",
        "  for column in null_values.columns:\n",
        "      for index, value in null_values[column].items():\n",
        "          if value:\n",
        "              if index not in null_list:\n",
        "                null_list.append(index)\n",
        "              print(f\"Null value found at index {index} in column {column}\")\n",
        "  return null_list"
      ],
      "metadata": {
        "id": "SvPT6Aw3Q6cb"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_train_X_y(train):\n",
        "  train['Number of Steps'] = pd.to_numeric(train['Number of Steps'], errors='coerce')\n",
        "  X = train.iloc[: , :-1]\n",
        "  y = train['Classification']\n",
        "  X['min'] = X['Max Norm'] - X['Range']\n",
        "  mapping = {'Running': 1, 'Walking': 0,'RUNNING': 1, 'WALKING': 0, }\n",
        "  y= y.map(mapping)\n",
        "  return X,y"
      ],
      "metadata": {
        "id": "HBF5wiRUNDfZ"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_test_X_y(test):\n",
        "  test['Number of Steps'] = pd.to_numeric(test['Number of Steps'], errors='coerce')\n",
        "  null_list = null_rows(test.iloc[: ,:-1])\n",
        "  test = test.drop(test.index[[i for i in null_list]])\n",
        "  X = test.iloc[: ,:-1]\n",
        "  y = test['Classification']\n",
        "  X['min'] = X['Max Norm'] - X['Range']\n",
        "  mapping = {'Running': 1, 'Walking': 0,'RUNNING': 1, 'WALKING': 0, }\n",
        "  y= y.map(mapping)\n",
        "  return X,y"
      ],
      "metadata": {
        "id": "dHZ95mvkOx9u"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = 'project_IOT.zip'\n",
        "bad_files = [\"6_run_3_1.csv\", \"6_run_4_1.csv\", \"6_walk_5_1.csv\", \"11_walk_1_1.csv\", \"11_walk_2_1.csv\", \"11_walk_3_1.csv\", \"11_walk_5_1.csv\"]\n",
        "train_list, test_list = split(file_name)\n",
        "train_df = train_test(train_list, bad_files)\n",
        "bad_train_index = find_bad_lines(train_df)\n",
        "train = clean_train(train_df, bad_train_index)\n",
        "X,y = return_train_X_y(train)"
      ],
      "metadata": {
        "id": "m2Mv3jj96ks9"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "VHOAufD91jFK",
        "outputId": "80aa2e0d-682d-4043-88d9-830904703143"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Mean Norm  Std Norm   Max Norm      Range  Number of Rows  \\\n",
              "0    11.444922  6.141134  23.795315  22.850169             578   \n",
              "1    11.830044  6.559816  30.842323  29.407611             580   \n",
              "2    10.109185  2.585022  19.302562  16.641134             957   \n",
              "3     9.997269  2.352843  19.361459  15.743932             972   \n",
              "4     9.892204  2.308173  19.144613  15.775904             945   \n",
              "..         ...       ...        ...        ...             ...   \n",
              "174  10.923497  2.076366  18.279182  11.545424             514   \n",
              "175  10.815573  2.210419  19.759722  13.842484             494   \n",
              "176  10.925536  2.238666  20.523560  13.248211             499   \n",
              "177  11.001765  2.384220  20.240121  13.138051             479   \n",
              "178  11.581722  6.253965  25.530691  23.713964             568   \n",
              "\n",
              "    Number of Steps Classification   \n",
              "0               100         Running  \n",
              "1               100         Running  \n",
              "2               100         Walking  \n",
              "3               100         Walking  \n",
              "4               100         Walking  \n",
              "..              ...             ...  \n",
              "174              80         Walking  \n",
              "175              75         Walking  \n",
              "176              75         Walking  \n",
              "177              77         Walking  \n",
              "178             100         Running  \n",
              "\n",
              "[179 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2ee69ad-a6af-4b75-9313-5d7b3326856a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean Norm</th>\n",
              "      <th>Std Norm</th>\n",
              "      <th>Max Norm</th>\n",
              "      <th>Range</th>\n",
              "      <th>Number of Rows</th>\n",
              "      <th>Number of Steps</th>\n",
              "      <th>Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.444922</td>\n",
              "      <td>6.141134</td>\n",
              "      <td>23.795315</td>\n",
              "      <td>22.850169</td>\n",
              "      <td>578</td>\n",
              "      <td>100</td>\n",
              "      <td>Running</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.830044</td>\n",
              "      <td>6.559816</td>\n",
              "      <td>30.842323</td>\n",
              "      <td>29.407611</td>\n",
              "      <td>580</td>\n",
              "      <td>100</td>\n",
              "      <td>Running</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.109185</td>\n",
              "      <td>2.585022</td>\n",
              "      <td>19.302562</td>\n",
              "      <td>16.641134</td>\n",
              "      <td>957</td>\n",
              "      <td>100</td>\n",
              "      <td>Walking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.997269</td>\n",
              "      <td>2.352843</td>\n",
              "      <td>19.361459</td>\n",
              "      <td>15.743932</td>\n",
              "      <td>972</td>\n",
              "      <td>100</td>\n",
              "      <td>Walking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.892204</td>\n",
              "      <td>2.308173</td>\n",
              "      <td>19.144613</td>\n",
              "      <td>15.775904</td>\n",
              "      <td>945</td>\n",
              "      <td>100</td>\n",
              "      <td>Walking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>10.923497</td>\n",
              "      <td>2.076366</td>\n",
              "      <td>18.279182</td>\n",
              "      <td>11.545424</td>\n",
              "      <td>514</td>\n",
              "      <td>80</td>\n",
              "      <td>Walking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>10.815573</td>\n",
              "      <td>2.210419</td>\n",
              "      <td>19.759722</td>\n",
              "      <td>13.842484</td>\n",
              "      <td>494</td>\n",
              "      <td>75</td>\n",
              "      <td>Walking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>10.925536</td>\n",
              "      <td>2.238666</td>\n",
              "      <td>20.523560</td>\n",
              "      <td>13.248211</td>\n",
              "      <td>499</td>\n",
              "      <td>75</td>\n",
              "      <td>Walking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>11.001765</td>\n",
              "      <td>2.384220</td>\n",
              "      <td>20.240121</td>\n",
              "      <td>13.138051</td>\n",
              "      <td>479</td>\n",
              "      <td>77</td>\n",
              "      <td>Walking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>11.581722</td>\n",
              "      <td>6.253965</td>\n",
              "      <td>25.530691</td>\n",
              "      <td>23.713964</td>\n",
              "      <td>568</td>\n",
              "      <td>100</td>\n",
              "      <td>Running</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>179 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2ee69ad-a6af-4b75-9313-5d7b3326856a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2ee69ad-a6af-4b75-9313-5d7b3326856a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2ee69ad-a6af-4b75-9313-5d7b3326856a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = train_test(test_list, bad_files)\n",
        "bad_test_index = find_bad_lines(test_df)\n",
        "test = clean_test(test_df, bad_test_index)\n",
        "X_test, y_test = return_test_X_y(test)"
      ],
      "metadata": {
        "id": "8Y937HyWbPa5"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running/Walking Classification"
      ],
      "metadata": {
        "id": "xfon3_zYfVWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaCa8uBugcZs",
        "outputId": "46fb17fc-e0bc-4a79-a68a-9fb1ec2c2304"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross validation for gboost parameters**"
      ],
      "metadata": {
        "id": "WLXrDF6sbC6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_g_boost = X.rename(columns={'Time [sec]':'Time'})\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "# Step 1: Define the base model\n",
        "model = xgb.XGBClassifier()\n",
        "\n",
        "# Step 2: Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.001],\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 4],\n",
        "    'subsample': [0.8, 0.9],\n",
        "    'reg_alpha': [0, 0.1],\n",
        "    'reg_lambda': [0, 0.1]\n",
        "}\n",
        "\n",
        "# Step 3: Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_g_boost, y)\n",
        "\n",
        "# Step 4: Get the best model and its hyperparameters\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Best Accuracy Score:\", best_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7JxkLWmghin",
        "outputId": "db067d78-c07f-442e-954b-daa99a990099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'subsample': 0.8}\n",
            "Best Accuracy Score: 0.6888820368156463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random forest cross validation**"
      ],
      "metadata": {
        "id": "EmK309XNb1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Step 1: Define the base model\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Step 2: Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 5],\n",
        "    'min_samples_split': [2],\n",
        "    'min_samples_leaf': [1],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "# Step 3: Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Step 4: Get the best model and its hyperparameters\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Best Accuracy Score:\", best_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAZPagT8a_Vg",
        "outputId": "0a58c06f-452a-4aca-9f64-f3cadb9ecdcb"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best Accuracy Score: 0.9288288288288289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predictions with the chosen parameters**"
      ],
      "metadata": {
        "id": "ZFlP__ubb57t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['Classification'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5mxbt944uNS",
        "outputId": "b720e149-c654-4f32-d152-5a6e801e7ecf"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Running', 'Walking', 'RUNNING', 'WALKING'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "gboost_model = xgb.XGBClassifier(learning_rate= 0.01, max_depth= 3, n_estimators = 100, reg_alpha= 0.1, reg_lambda=0.1, subsample= 0.8)\n",
        "gboost_model.fit(X, y)\n",
        "rf_model = RandomForestClassifier(max_features= 'sqrt', min_samples_leaf= 1, min_samples_split=2, n_estimators=200)\n",
        "rf_model.fit(X, y)"
      ],
      "metadata": {
        "id": "ASmVgtWqbW1O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "cb0c3044-1dad-489c-b356-e0a7bb99cc7f"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rf = rf_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"random forest rows Accuracy:\", accuracy*100)\n",
        "# X_test_boost = X_test.rename(columns={'Time [sec]':'Time'})\n",
        "y_pred_gboost = gboost_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred_gboost)\n",
        "print(\"gboost rows Accuracy:\", accuracy*100)"
      ],
      "metadata": {
        "id": "jwkFgK-sbMoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4e4729-dcb7-496f-8b15-1961d3c38f90"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random forest rows Accuracy: 97.61904761904762\n",
            "gboost rows Accuracy: 95.23809523809523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_on_file(bad_files):\n",
        "  count = 0\n",
        "  for i,name in enumerate(test_list):\n",
        "    if 'run' in name:\n",
        "      classification = 1\n",
        "    else:\n",
        "      classification = 0\n",
        "    test_file = train_test([name], bad_files)\n",
        "    bad_test_file_index = find_bad_lines(test_file)\n",
        "    test_file_cleaned =  test_file.drop(test_file.index[[i for i in bad_test_file_index]])\n",
        "    if 'Time[sec]' in test_file_cleaned.columns:\n",
        "      test_file_cleaned  = test_file_cleaned .rename(columns={'Time[sec]': 'Time [sec]'})\n",
        "    for column in test_file_cleaned.columns[1::]:\n",
        "        test_file_cleaned  = test_file_cleaned .rename(columns={column:column.strip()})\n",
        "    X_test,_ = return_test_X_y(test_file_cleaned)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    if round(np.mean(y_pred))==classification:\n",
        "      count+=1\n",
        "  print(f'random forest accuracy: {count*100/len(test_list)}%')"
      ],
      "metadata": {
        "id": "rV6OnETSViLc"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_on_gboost(bad_files):\n",
        "  count = 0\n",
        "  for i,name in enumerate(test_list):\n",
        "    if 'run' in name:\n",
        "      classification = 1\n",
        "    else:\n",
        "      classification = 0\n",
        "    test_file = train_test([name], bad_files)\n",
        "    bad_test_file_index = find_bad_lines(test_file)\n",
        "    test_file_cleaned =  test_file.drop(test_file.index[[i for i in bad_test_file_index]])\n",
        "    if 'Time[sec]' in test_file_cleaned.columns:\n",
        "      test_file_cleaned  = test_file_cleaned .rename(columns={'Time[sec]': 'Time [sec]'})\n",
        "    for column in test_file_cleaned.columns[1::]:\n",
        "        test_file_cleaned  = test_file_cleaned .rename(columns={column:column.strip()})\n",
        "    X_test,_ = return_test_X_y(test_file_cleaned)\n",
        "    # X_test_boost = X_test.rename(columns={'Time [sec]':'Time'})\n",
        "    y_pred = gboost_model.predict(X_test)\n",
        "    if round(np.mean(y_pred))==classification:\n",
        "      count+=1\n",
        "  print(f'gboost accuracy: {count*100/len(test_list)}%')"
      ],
      "metadata": {
        "id": "mGiZibSUhcHl"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_on_gboost(bad_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0lYLpbAho4B",
        "outputId": "baa5a0be-f81b-4e48-c4dd-70eb539d31ab"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gboost accuracy: 95.23809523809524%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_on_file(bad_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84AeHeQdbZkS",
        "outputId": "036b46e7-d0e0-4b8e-8b15-c752033ea056"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random forest accuracy: 97.61904761904762%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NUmber of Steps Classification"
      ],
      "metadata": {
        "id": "GrNJvifDfG7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_steps(curr_list, bad_files):\n",
        "  mean_norm_list = []\n",
        "  std_norm_list = []\n",
        "  max_norm_list = []\n",
        "  range_list = []\n",
        "  classification_list = []\n",
        "  number_of_steps_list = []\n",
        "  num_rows = []\n",
        "  for i,name in enumerate(curr_list):\n",
        "    if name in bad_files:\n",
        "        data = pd.read_csv(name, skiprows=6)\n",
        "        head = pd.read_csv(name, nrows=4)\n",
        "    else:\n",
        "        data = pd.read_csv(name,skiprows=5)\n",
        "        head = pd.read_csv(name, nrows=3)\n",
        "    classification = head.iloc[1,1]\n",
        "    steps = head.iloc[2,1]\n",
        "    data['Norm'] = [\"\" for i in range(len(data))]\n",
        "    data['Classification'] = [classification for i in range(len(data))]\n",
        "    for row in range(len(data)):\n",
        "      x,y,z = data.iloc[row, 1], data.iloc[row, 2], data.iloc[row, 3]\n",
        "      if  not is_float(x) or not is_float(y) or not is_float(z):\n",
        "        data.drop(data.index[row])\n",
        "      else:\n",
        "        data['Norm'].iloc[row] = norm(x,y,z)\n",
        "    mean_norm_list.append(np.mean(data['Norm']))\n",
        "    std_norm_list.append(np.std(data['Norm']))\n",
        "    max_norm_list.append(np.max(data['Norm']))\n",
        "    range_list.append(np.max(data['Norm']) - np.min(data['Norm']))\n",
        "    classification_list.append(data['Classification'][0])\n",
        "    num_rows.append(len(data))\n",
        "    number_of_steps_list.append(steps)\n",
        "  data_final = {\n",
        "      'Mean Norm': mean_norm_list,\n",
        "      'Std Norm': std_norm_list,\n",
        "      'Max Norm': max_norm_list,\n",
        "      'Range': range_list,\n",
        "      'Classification': classification_list,\n",
        "      'Number of Rows': num_rows,\n",
        "      'Number of Steps': number_of_steps_list\n",
        "  }\n",
        "  # Create the DataFrame\n",
        "  df = pd.DataFrame(data_final)\n",
        "  return df"
      ],
      "metadata": {
        "id": "SWP_-AAC_1-J"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = 'project_IOT.zip'\n",
        "bad_files = [\"6_run_3_1.csv\", \"6_run_4_1.csv\", \"6_walk_5_1.csv\", \"11_walk_1_1.csv\", \"11_walk_2_1.csv\", \"11_walk_3_1.csv\", \"11_walk_5_1.csv\"]\n",
        "train_list, test_list = split(file_name)\n",
        "train_df = train_test(train_list, bad_files)\n",
        "bad_train_index = find_bad_lines(train_df)\n",
        "train = clean_train(train_df, bad_train_index)\n",
        "X_train,y_train = X_y_steps(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxMbFXbH_2Q7",
        "outputId": "0dbec396-f556-45aa-8be9-2d5a72e8775d"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Mean Norm', 'Std Norm', 'Max Norm', 'Range', 'Classification',\n",
            "       'Number of Rows', 'min'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def X_y_steps(df):\n",
        "  df['Number of Steps'] = pd.to_numeric(df['Number of Steps'], errors='coerce')\n",
        "  # train['ACC X'] = pd.to_numeric(train['ACC X'], errors='coerce')\n",
        "  # train['ACC Y'] = pd.to_numeric(train['ACC Y'], errors='coerce')\n",
        "  # train['ACC Z'] = pd.to_numeric(train['ACC Z'], errors='coerce')\n",
        "  # train['Norm'] = pd.to_numeric(train['Norm'], errors='coerce')\n",
        "  mapping = {'Running': 1, 'Walking': 0,'RUNNING': 1, 'WALKING': 0, }\n",
        "  df['Classification'] = df['Classification'].map(mapping)\n",
        "  # Separate the target variable 'y' and the feature matrix 'X'\n",
        "  X = df.iloc[:,:-1]  # Columns 1, 2, 3, 4, and 6\n",
        "  X['min'] = X['Max Norm'] - X['Range']\n",
        "  y = df.iloc[:, -1]  # Column 5\n",
        "  return X,y"
      ],
      "metadata": {
        "id": "SnFmoSAq7tVG"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = train_test_steps(test_list, bad_files)\n",
        "bad_test_index = find_bad_lines(test_df)\n",
        "test = clean_test(test_df, bad_test_index)\n",
        "X_t, y_t = X_y_steps(test)"
      ],
      "metadata": {
        "id": "FGpgZbhQ7lpO"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "gb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "\n",
        "# Fit the regressor to your training data\n",
        "gb_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained regressor to make predictions\n",
        "y_pred = gb_regressor.predict(X_t)\n",
        "\n",
        "# Evaluate the model using mean squared error\n",
        "rmse = np.sqrt(mean_squared_error(y_t, y_pred))\n",
        "print(\"Root Mean Squared Error:\", rmse)"
      ],
      "metadata": {
        "id": "8mq6WYUifOEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c9ee12-eff0-44f6-f509-f783d28fe330"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error: 16.320297885987067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qFQyKBQS9oFV"
      },
      "execution_count": 172,
      "outputs": []
    }
  ]
}